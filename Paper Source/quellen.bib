% This file was created with Citavi 6.2.0.12

@proceedings{.18.05.200921.05.2009,
 year = {18.05.2009 - 21.05.2009},
 title = {2009 IEEE Congress on Evolutionary Computation},
 publisher = {IEEE},
 isbn = {978-1-4244-2958-5}
}


@misc{AlanMcIntyreandMattKalladaandCesarG.MiguelandCarolinaFeherdaSilva.,
 author = {{Alan McIntyre and Matt Kallada and Cesar G. Miguel and Carolina Feher da Silva}},
 title = {neat-python},
 url = {https://github.com/CodeReclaimers/neat-python}
}


@book{Braspenning.1995,
 author = {Braspenning, P. J.},
 year = {1995},
 title = {Artificial neural networks: An introduction to ANN theory and practice},
 url = {http://www.springerlink.com/content/w4118k11x171},
 address = {Berlin},
 volume = {931},
 publisher = {Springer},
 isbn = {978-3-540-59488-8},
 series = {Lecture notes in computer science},
 doi = {10.1007/BFb0027019}
}


@inproceedings{Clune.18.05.200921.05.2009,
 author = {Clune, Jeff and Beckmann, Benjamin E. and Ofria, Charles and Pennock, Robert T.},
 title = {Evolving coordinated quadruped gaits with the HyperNEAT generative encoding},
 pages = {2764--2771},
 publisher = {IEEE},
 isbn = {978-1-4244-2958-5},
 booktitle = {2009 IEEE Congress on Evolutionary Computation},
 year = {18.05.2009 - 21.05.2009},
 doi = {10.1109/CEC.2009.4983289}
}


@misc{Desell.16.03.2017,
 abstract = {This work presents a new algorithm called evolutionary exploration of augmenting convolutional topologies (EXACT), which is capable of evolving the structure of convolutional neural networks (CNNs). EXACT is in part modeled after the neuroevolution of augmenting topologies (NEAT) algorithm, with notable exceptions to allow it to scale to large scale distributed computing environments and evolve networks with convolutional filters. In addition to multithreaded and MPI versions, EXACT has been implemented as part of a BOINC volunteer computing project, allowing large scale evolution. During a period of two months, over 4,500 volunteered computers on the Citizen Science Grid trained over 120,000 CNNs and evolved networks reaching 98.32{\%} test data accuracy on the MNIST handwritten digits dataset. These results are even stronger as the backpropagation strategy used to train the CNNs was fairly rudimentary (ReLU units, L2 regularization and Nesterov momentum) and these were initial test runs done without refinement of the backpropagation hyperparameters. Further, the EXACT evolutionary strategy is independent of the method used to train the CNNs, so they could be further improved by advanced techniques like elastic distortions, pretraining and dropout. The evolved networks are also quite interesting, showing {\textquotedbl}organic{\textquotedbl} structures and significant differences from standard human designed architectures.},
 author = {Desell, Travis},
 date = {16.03.2017},
 title = {Large Scale Evolution of Convolutional Neural Networks Using Volunteer  Computing},
 url = {http://arxiv.org/pdf/1703.05422v1}
}


@misc{Hermawanto.16.08.2013,
 abstract = {This paper explains genetic algorithm for novice in this field. Basic philosophy of genetic algorithm and its flowchart are described. Step by step numerical computation of genetic algorithm for solving simple mathematical equality problem will be briefly explained},
 author = {Hermawanto, Denny},
 date = {16.08.2013},
 title = {Genetic Algorithm for Solving Simple Mathematical Equality Problem},
 url = {http://arxiv.org/pdf/1308.4675v2}
}


@misc{Kingma.22.12.2014,
 abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
 author = {Kingma, Diederik P. and Ba, Jimmy},
 date = {22.12.2014},
 title = {Adam: A Method for Stochastic Optimization},
 url = {http://arxiv.org/pdf/1412.6980v9}
}


@book{Rojas.1996,
 abstract = {Artificial neural networks are an alternative computational paradigm with roots in neurobiology which has attracted increasing interest in recent years. This book is a comprehensive introduction to the topic that stresses the systematic development of the underlying theory. Starting from simple threshold elements, more advanced topics are introduced, such as multilayer networks, efficient learning methods, recurrent networks, and self-organization. The various branches of neural network theory are interrelated closely and quite often unexpectedly, so the chapters treat the underlying connection between neural models and offer a unified view of the current state of research in the field. The book has been written for anyone interested in understanding artificial neural networks or in learning more about them. The only mathematical tools needed are those learned during the first two years at university. The text contains more than 300 figures to stimulate the intuition of the reader and to illustrate the kinds of computation performed by neural networks. Material from the book has been used successfully for courses in Germany, Austria and the United States},
 author = {Rojas, Ra{\'u}l},
 year = {1996},
 title = {Neural Networks: A Systematic Introduction},
 url = {http://dx.doi.org/10.1007/978-3-642-61068-4},
 address = {Berlin and Heidelberg},
 publisher = {Springer},
 isbn = {978-3-642-61068-4},
 doi = {10.1007/978-3-642-61068-4}
}


@misc{Salimans.11.03.2017,
 abstract = {We explore the use of Evolution Strategies (ES), a class of black box optimization algorithms, as an alternative to popular MDP-based RL techniques such as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show that ES is a viable solution strategy that scales extremely well with the number of CPUs available: By using a novel communication strategy based on common random numbers, our ES implementation only needs to communicate scalars, making it possible to scale to over a thousand parallel workers. This allows us to solve 3D humanoid walking in 10 minutes and obtain competitive results on most Atari games after one hour of training. In addition, we highlight several advantages of ES as a black box optimization technique: it is invariant to action frequency and delayed rewards, tolerant of extremely long horizons, and does not need temporal discounting or value function approximation.},
 author = {Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
 date = {11.03.2017},
 title = {Evolution Strategies as a Scalable Alternative to Reinforcement Learning},
 url = {http://arxiv.org/pdf/1703.03864v2}
}


@article{Silver.2016,
 abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses 'value networks' to evaluate board positions and 'policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8{\%} winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
 author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and {van den Driessche}, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
 year = {2016},
 title = {Mastering the game of Go with deep neural networks and tree search},
 pages = {484--489},
 volume = {529},
 number = {7587},
 journal = {Nature},
 doi = {10.1038/nature16961}
}


@article{Stanley.2002,
 abstract = {An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, NeuroEvolution of Augmenting Topologies (NEAT), which outperforms the best fixed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efficiency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is significantly faster learning. NEAT is also an important contribution to GAs because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution.},
 author = {Stanley, Kenneth O. and Miikkulainen, Risto},
 year = {2002},
 title = {Evolving neural networks through augmenting topologies},
 pages = {99--127},
 volume = {10},
 number = {2},
 issn = {1063-6560},
 journal = {Evolutionary computation},
 doi = {10.1162/106365602320169811}
}


@article{Stanley.2019,
 abstract = {Much of recent machine learning has focused on deep learning, in which neural network weights are trained through variants of stochastic gradient descent. An alternative approach comes from the field of neuroevolution, which harnesses evolutionary algorithms to optimize neural networks, inspired by the fact that natural brains themselves are the products of an evolutionary process. Neuroevolution enables important capabilities that are typically unavailable to gradient-based approaches, including learning neural network building blocks (for example activation functions), hyperparameters, architectures and even the algorithms for learning themselves. Neuroevolution also differs from deep learning (and deep reinforcement learning) by maintaining a population of solutions during search, enabling extreme exploration and massive parallelization. Finally, because neuroevolution research has (until recently) developed largely in isolation from gradient-based neural network research, it has developed many unique and effective techniques that should be effective in other machine learning areas too. This Review looks at several key aspects of modern neuroevolution, including large-scale computing, the benefits of novelty and diversity, the power of indirect encoding, and the field's contributions to meta-learning and architecture search. Our hope is to inspire renewed interest in the field as it meets the potential of the increasing computation available today, to highlight how many of its ideas can provide an exciting resource for inspiration and hybridization to the deep learning, deep reinforcement learning and machine learning communities, and to explain how neuroevolution could prove to be a critical tool in the long-term pursuit of artificial general intelligence.},
 author = {Stanley, Kenneth O. and Clune, Jeff and Lehman, Joel and Miikkulainen, Risto},
 year = {2019},
 title = {Designing neural networks through neuroevolution},
 url = {https://doi.org/10.1038/s42256-018-0006-z},
 pages = {24--35},
 volume = {1},
 number = {1},
 issn = {2522-5839},
 journal = {Nature Machine Intelligence},
 doi = {10.1038/s42256-018-0006-z}
}


